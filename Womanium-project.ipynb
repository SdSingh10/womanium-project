{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e74846a-9142-4d67-8365-0476805809c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           dt  LandAverageTemperature  LandAverageTemperatureUncertainty  \\\n",
      "0  1750-01-01                   3.034                              3.574   \n",
      "1  1750-02-01                   3.083                              3.702   \n",
      "2  1750-03-01                   5.626                              3.076   \n",
      "3  1750-04-01                   8.490                              2.451   \n",
      "4  1750-05-01                  11.573                              2.072   \n",
      "\n",
      "   LandMaxTemperature  LandMaxTemperatureUncertainty  LandMinTemperature  \\\n",
      "0                 NaN                            NaN                 NaN   \n",
      "1                 NaN                            NaN                 NaN   \n",
      "2                 NaN                            NaN                 NaN   \n",
      "3                 NaN                            NaN                 NaN   \n",
      "4                 NaN                            NaN                 NaN   \n",
      "\n",
      "   LandMinTemperatureUncertainty  LandAndOceanAverageTemperature  \\\n",
      "0                            NaN                             NaN   \n",
      "1                            NaN                             NaN   \n",
      "2                            NaN                             NaN   \n",
      "3                            NaN                             NaN   \n",
      "4                            NaN                             NaN   \n",
      "\n",
      "   LandAndOceanAverageTemperatureUncertainty  \n",
      "0                                        NaN  \n",
      "1                                        NaN  \n",
      "2                                        NaN  \n",
      "3                                        NaN  \n",
      "4                                        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\chawl\\Downloads\\archive (2)\\GlobalTemperatures.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "992b5ce7-27bb-4482-9b77-d99dda0856b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  LandAndOceanAverageTemperature  \\\n",
      "0  1750                             NaN   \n",
      "1  1750                             NaN   \n",
      "2  1750                             NaN   \n",
      "3  1750                             NaN   \n",
      "4  1750                             NaN   \n",
      "\n",
      "   LandAndOceanAverageTemperatureUncertainty  \n",
      "0                                        NaN  \n",
      "1                                        NaN  \n",
      "2                                        NaN  \n",
      "3                                        NaN  \n",
      "4                                        NaN  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'dt' column to datetime format and extract the year\n",
    "df['Year'] = pd.to_datetime(df['dt']).dt.year\n",
    "\n",
    "# Now let's focus on the global temperature columns\n",
    "# Note: 'LandAndOceanAverageTemperature' seems to be the global temperature\n",
    "global_temp_df = df[['Year', 'LandAndOceanAverageTemperature', 'LandAndOceanAverageTemperatureUncertainty']].copy()\n",
    "\n",
    "# Display the first few rows of the relevant data\n",
    "print(global_temp_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77231acf-1b8c-49e2-a666-8bcfbc10b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  LandAndOceanAverageTemperature  \\\n",
      "1200  1850                          12.833   \n",
      "1201  1850                          13.588   \n",
      "1202  1850                          14.043   \n",
      "1203  1850                          14.667   \n",
      "1204  1850                          15.507   \n",
      "\n",
      "      LandAndOceanAverageTemperatureUncertainty  \n",
      "1200                                      0.367  \n",
      "1201                                      0.414  \n",
      "1202                                      0.341  \n",
      "1203                                      0.267  \n",
      "1204                                      0.249  \n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "global_temp_df = global_temp_df.dropna()\n",
    "\n",
    "# Display the cleaned data\n",
    "print(global_temp_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e20a82b2-db30-402a-a578-b7186e6d17d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  Temp_Anomaly\n",
      "1200  1850     -2.379566\n",
      "1201  1850     -1.624566\n",
      "1202  1850     -1.169566\n",
      "1203  1850     -0.545566\n",
      "1204  1850      0.294434\n"
     ]
    }
   ],
   "source": [
    "# Calculate temperature anomalies (deviation from the mean)\n",
    "global_temp_df['Temp_Anomaly'] = global_temp_df['LandAndOceanAverageTemperature'] - global_temp_df['LandAndOceanAverageTemperature'].mean()\n",
    "\n",
    "# Select features for the model\n",
    "features = global_temp_df[['Year', 'Temp_Anomaly']]\n",
    "print(features.head())\n",
    "\n",
    "# Now let's prepare this data for use in a VQC model (as previously outlined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c22264f-705a-448f-bc34-3a5850885b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features[['Temp_Anomaly']])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    scaled_features, features['Year'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to binary for a simple classification task\n",
    "train_labels = (train_labels > train_labels.mean()).astype(int)\n",
    "test_labels = (test_labels > test_labels.mean()).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd65d5ac-bffd-49f3-884c-f9ef6bbc2535",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The ZZFeatureMap contains 2-local interactions and cannot be defined for less than 2 qubits. You provided 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Define the feature map and ansatz\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_features \u001b[38;5;241m=\u001b[39m train_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m feature_map \u001b[38;5;241m=\u001b[39m \u001b[43mZZFeatureMap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_dimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m ansatz \u001b[38;5;241m=\u001b[39m RealAmplites(num_qubits\u001b[38;5;241m=\u001b[39mnum_features, reps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Define the optimizer\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qiskit\\circuit\\library\\data_preparation\\zz_feature_map.py:100\u001b[0m, in \u001b[0;36mZZFeatureMap.__init__\u001b[1;34m(self, feature_dimension, reps, entanglement, data_map_func, parameter_prefix, insert_barriers, name)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new second-order Pauli-Z expansion.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    ValueError: If the feature dimension is smaller than 2.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_dimension \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe ZZFeatureMap contains 2-local interactions and cannot be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefined for less than 2 qubits. You provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_dimension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m     )\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    106\u001b[0m     feature_dimension\u001b[38;5;241m=\u001b[39mfeature_dimension,\n\u001b[0;32m    107\u001b[0m     reps\u001b[38;5;241m=\u001b[39mreps,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    114\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: The ZZFeatureMap contains 2-local interactions and cannot be defined for less than 2 qubits. You provided 1."
     ]
    }
   ],
   "source": [
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "\n",
    "# Rest of your code...\n",
    "import time\n",
    "\n",
    "# Define the feature map and ansatz\n",
    "num_features = train_features.shape[1]\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
    "ansatz = RealAmplites(num_qubits=num_features, reps=3)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = COBYLA(maxiter=100)\n",
    "\n",
    "# Define the sampler\n",
    "sampler = Sampler()\n",
    "\n",
    "# Initialize and train the VQC\n",
    "vqc = VQC(sampler=sampler, feature_map=feature_map, ansatz=ansatz, optimizer=optimizer)\n",
    "\n",
    "start = time.time()\n",
    "vqc.fit(train_features, train_labels)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Training time: {elapsed:.2f} seconds\")\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = vqc.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4dca5a5-ad07-47d1-8262-e3ce12f02869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  LandAndOceanAverageTemperature  Temp_Anomaly\n",
      "1200  1850                          12.833     -2.379566\n",
      "1201  1850                          13.588     -1.624566\n",
      "1202  1850                          14.043     -1.169566\n",
      "1203  1850                          14.667     -0.545566\n",
      "1204  1850                          15.507      0.294434\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(r'C:\\Users\\chawl\\Downloads\\archive (2)\\GlobalTemperatures.csv')\n",
    "\n",
    "# Convert the 'dt' column to datetime format and extract the year\n",
    "df['Year'] = pd.to_datetime(df['dt']).dt.year\n",
    "\n",
    "# Calculate temperature anomalies (deviation from the mean)\n",
    "df['Temp_Anomaly'] = df['LandAndOceanAverageTemperature'] - df['LandAndOceanAverageTemperature'].mean()\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Select the features and target variable\n",
    "train_features = df[['Year', 'LandAndOceanAverageTemperature', 'Temp_Anomaly']]\n",
    "train_labels = (df['LandAndOceanAverageTemperature'] > df['LandAndOceanAverageTemperature'].mean()).astype(int)\n",
    "\n",
    "print(train_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a578914c-6950-425f-be0a-ec43fb1ac28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -0.8605919  -0.8605919 ]\n",
      " [-1.         -0.56658879 -0.56658879]\n",
      " [-1.         -0.3894081  -0.3894081 ]\n",
      " [-1.         -0.14641745 -0.14641745]\n",
      " [-1.          0.18068536  0.18068536]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "print(train_features[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb24bb4c-81da-4e7e-b51e-ca30070f5edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5964912280701754\n"
     ]
    }
   ],
   "source": [
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'train_features' and 'train_labels' are already defined\n",
    "# Define the feature map and ansatz\n",
    "num_features = train_features.shape[1]\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = COBYLA(maxiter=100)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert y_train and y_test to numpy arrays if they are not already\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Create the VQC model\n",
    "vqc = VQC(feature_map=feature_map, ansatz=ansatz, optimizer=optimizer, sampler=Sampler())\n",
    "\n",
    "# Train the VQC model\n",
    "vqc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "score = vqc.score(X_test, y_test)\n",
    "print(f\"Test accuracy: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be3c3e-01bc-4f89-892a-aa48f7a39ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
